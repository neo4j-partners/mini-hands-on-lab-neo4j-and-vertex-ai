{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rQ6G65n6OxV"
   },
   "source": [
    "# VertexAI Auto ML Embedding\n",
    "In this notebook, we'll use the awesome Vertex AI AutoML to train a model using our graph embedding as an additional feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9998,
     "status": "ok",
     "timestamp": 1681113488488,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "id": "zWcDg3rtFSTg"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet google-cloud-storage google-cloud-aiplatform python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OL79OSi1FSTh"
   },
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681113149850,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "gather": {
     "logged": 1669345050388
    },
    "id": "7nS_fiKEFSTh"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDT66GlIFSTh"
   },
   "source": [
    "## Vertex AI Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaP3KG5bFSTh"
   },
   "source": [
    "### Workspace details\n",
    "Lets define the variables to connect to VertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681113268018,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "id": "ZBdYrgK4GHOH"
   },
   "outputs": [],
   "source": [
    "load_dotenv('config.env', override=True)\n",
    "REGION = os.getenv('GCLOUD_REGION')\n",
    "shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "\n",
    "STORAGE_BUCKET = PROJECT_ID + '-fsi'\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create Tabular dataset objects for our raw & embedding data below. These datasets refer to the Cloud Storage CSV files we just uploaded in the previous Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "error",
     "timestamp": 1681113462053,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "gather": {
     "logged": 1669345052512
    },
    "id": "7SoC49BeFSTh",
    "outputId": "5a2cd7ea-4a27-4140-fdb9-7112bc5f83a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TabularDataset\n",
      "Create TabularDataset backing LRO: projects/934983306258/locations/us-central1/datasets/6969661271960453120/operations/6406713311403966464\n",
      "TabularDataset created. Resource name: projects/934983306258/locations/us-central1/datasets/6969661271960453120\n",
      "To use this TabularDataset in another session:\n",
      "ds = aiplatform.TabularDataset('projects/934983306258/locations/us-central1/datasets/6969661271960453120')\n",
      "\tDataset: \"claims-raw\"\n",
      "\tname: \"projects/934983306258/locations/us-central1/datasets/6969661271960453120\"\n",
      "Creating TabularDataset\n",
      "Create TabularDataset backing LRO: projects/934983306258/locations/us-central1/datasets/7059733264507863040/operations/5963108748107972608\n",
      "TabularDataset created. Resource name: projects/934983306258/locations/us-central1/datasets/7059733264507863040\n",
      "To use this TabularDataset in another session:\n",
      "ds = aiplatform.TabularDataset('projects/934983306258/locations/us-central1/datasets/7059733264507863040')\n",
      "\tDataset: \"claims-embedding\"\n",
      "\tname: \"projects/934983306258/locations/us-central1/datasets/7059733264507863040\"\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "baseline_dataset = aiplatform.TabularDataset.create(\n",
    "    display_name=\"claims-raw\",\n",
    "    gcs_source=os.path.join(\"gs://\", STORAGE_BUCKET, 'insurance_fraud', 'baseline.csv'),\n",
    ")\n",
    "baseline_dataset.wait()\n",
    "\n",
    "print(f'\\tDataset: \"{baseline_dataset.display_name}\"')\n",
    "print(f'\\tname: \"{baseline_dataset.resource_name}\"')\n",
    "\n",
    "embedding_dataset = aiplatform.TabularDataset.create(\n",
    "    display_name=\"claims-embedding\",\n",
    "    gcs_source=os.path.join(\"gs://\", STORAGE_BUCKET, 'insurance_fraud', 'embedding.csv'),\n",
    ")\n",
    "embedding_dataset.wait()\n",
    "\n",
    "print(f'\\tDataset: \"{embedding_dataset.display_name}\"')\n",
    "print(f'\\tname: \"{embedding_dataset.resource_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Run Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets define the numeric columns in our baseline dataset and define the job that will help us classify fraudulent claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['provider',\n",
       " 'potentialFraudInd',\n",
       " 'inpationFraction',\n",
       " 'renalDiseaseIndicatorNumEnc',\n",
       " 'chronicCondAlzheimerEnc',\n",
       " 'chronicCondHeartfailureEnc',\n",
       " 'chronicCondKidneyDiseaseEnc',\n",
       " 'chronicCondCancerEnc',\n",
       " 'chronicCondObstrPulmonaryEnc',\n",
       " 'chronicCondDepressionEnc',\n",
       " 'chronicCondDiabetesEnc',\n",
       " 'chronicCondIschemicHeartEnc',\n",
       " 'chronicCondOsteoporasisEnc',\n",
       " 'chronicCondrheumatoidarthritisEnc',\n",
       " 'chronicCondstrokeEnc',\n",
       " 'chronicCondAlzheimerIndEnc',\n",
       " 'chronicCondHeartfailureIndEnc',\n",
       " 'chronicCondKidneyDiseaseIndEnc',\n",
       " 'chronicCondCancerIndEnc',\n",
       " 'chronicCondObstrPulmonaryIndEnc',\n",
       " 'chronicCondDepressionIndEnc',\n",
       " 'chronicCondDiabetesIndEnc',\n",
       " 'chronicCondIschemicHeartIndEnc',\n",
       " 'chronicCondOsteoporasisIndEnc',\n",
       " 'chronicCondrheumatoidarthritisIndEnc',\n",
       " 'chronicCondstrokeIndEnc',\n",
       " 'claimCount',\n",
       " 'avgClaimAmtReimbursed',\n",
       " 'providerId']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DATA_DIR = 'data/'\n",
    "baseline_cols = list(pd.read_csv(DATA_DIR + 'baseline.csv').columns)\n",
    "baseline_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_baseline_cols = [i for i in baseline_cols if i not in ['provider', 'providerId']]\n",
    "baseline_column_specs = {column: \"numeric\" for column in num_baseline_cols}\n",
    "\n",
    "raw_job = aiplatform.AutoMLTabularTrainingJob(\n",
    "    display_name=\"train-fraud-baseline-automl\",\n",
    "    optimization_prediction_type=\"classification\",\n",
    "    column_specs=baseline_column_specs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/8759625932366413824?project=934983306258\n",
      "AutoMLTabularTrainingJob projects/934983306258/locations/us-central1/trainingPipelines/8759625932366413824 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "raw_model = raw_job.run(\n",
    "    dataset=baseline_dataset,\n",
    "    target_column=\"potentialFraudInd\",\n",
    "    training_fraction_split=0.6,\n",
    "    validation_fraction_split=0.2,\n",
    "    test_fraction_split=0.2,\n",
    "    model_display_name=\"train-fraud-baseline-automl\",\n",
    "    disable_early_stopping=False,\n",
    "    budget_milli_node_hours=1000,\n",
    "    sync = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Run with Embedding Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, let's define the classifier job for the embedding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['provider',\n",
       " 'potentialFraudInd',\n",
       " 'inpationFraction',\n",
       " 'renalDiseaseIndicatorNumEnc',\n",
       " 'chronicCondAlzheimerEnc',\n",
       " 'chronicCondHeartfailureEnc',\n",
       " 'chronicCondKidneyDiseaseEnc',\n",
       " 'chronicCondCancerEnc',\n",
       " 'chronicCondObstrPulmonaryEnc',\n",
       " 'chronicCondDepressionEnc',\n",
       " 'chronicCondDiabetesEnc',\n",
       " 'chronicCondIschemicHeartEnc',\n",
       " 'chronicCondOsteoporasisEnc',\n",
       " 'chronicCondrheumatoidarthritisEnc',\n",
       " 'chronicCondstrokeEnc',\n",
       " 'chronicCondAlzheimerIndEnc',\n",
       " 'chronicCondHeartfailureIndEnc',\n",
       " 'chronicCondKidneyDiseaseIndEnc',\n",
       " 'chronicCondCancerIndEnc',\n",
       " 'chronicCondObstrPulmonaryIndEnc',\n",
       " 'chronicCondDepressionIndEnc',\n",
       " 'chronicCondDiabetesIndEnc',\n",
       " 'chronicCondIschemicHeartIndEnc',\n",
       " 'chronicCondOsteoporasisIndEnc',\n",
       " 'chronicCondrheumatoidarthritisIndEnc',\n",
       " 'chronicCondstrokeIndEnc',\n",
       " 'claimCount',\n",
       " 'avgClaimAmtReimbursed',\n",
       " 'providerId',\n",
       " 'groupCodeEmb_0',\n",
       " 'groupCodeEmb_1',\n",
       " 'groupCodeEmb_2',\n",
       " 'groupCodeEmb_3',\n",
       " 'groupCodeEmb_4',\n",
       " 'groupCodeEmb_5',\n",
       " 'groupCodeEmb_6',\n",
       " 'groupCodeEmb_7',\n",
       " 'groupCodeEmb_8',\n",
       " 'groupCodeEmb_9',\n",
       " 'groupCodeEmb_10',\n",
       " 'groupCodeEmb_11',\n",
       " 'groupCodeEmb_12',\n",
       " 'groupCodeEmb_13',\n",
       " 'groupCodeEmb_14',\n",
       " 'groupCodeEmb_15',\n",
       " 'groupCodeEmb_16',\n",
       " 'groupCodeEmb_17',\n",
       " 'groupCodeEmb_18',\n",
       " 'groupCodeEmb_19',\n",
       " 'groupCodeEmb_20',\n",
       " 'groupCodeEmb_21',\n",
       " 'groupCodeEmb_22',\n",
       " 'groupCodeEmb_23',\n",
       " 'groupCodeEmb_24',\n",
       " 'groupCodeEmb_25',\n",
       " 'groupCodeEmb_26',\n",
       " 'groupCodeEmb_27',\n",
       " 'groupCodeEmb_28',\n",
       " 'groupCodeEmb_29',\n",
       " 'groupCodeEmb_30',\n",
       " 'groupCodeEmb_31',\n",
       " 'diagCodeEmb_0',\n",
       " 'diagCodeEmb_1',\n",
       " 'diagCodeEmb_2',\n",
       " 'diagCodeEmb_3',\n",
       " 'diagCodeEmb_4',\n",
       " 'diagCodeEmb_5',\n",
       " 'diagCodeEmb_6',\n",
       " 'diagCodeEmb_7',\n",
       " 'diagCodeEmb_8',\n",
       " 'diagCodeEmb_9',\n",
       " 'diagCodeEmb_10',\n",
       " 'diagCodeEmb_11',\n",
       " 'diagCodeEmb_12',\n",
       " 'diagCodeEmb_13',\n",
       " 'diagCodeEmb_14',\n",
       " 'diagCodeEmb_15',\n",
       " 'diagCodeEmb_16',\n",
       " 'diagCodeEmb_17',\n",
       " 'diagCodeEmb_18',\n",
       " 'diagCodeEmb_19',\n",
       " 'diagCodeEmb_20',\n",
       " 'diagCodeEmb_21',\n",
       " 'diagCodeEmb_22',\n",
       " 'diagCodeEmb_23',\n",
       " 'diagCodeEmb_24',\n",
       " 'diagCodeEmb_25',\n",
       " 'diagCodeEmb_26',\n",
       " 'diagCodeEmb_27',\n",
       " 'diagCodeEmb_28',\n",
       " 'diagCodeEmb_29',\n",
       " 'diagCodeEmb_30',\n",
       " 'diagCodeEmb_31']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMLTabularTrainingJob projects/934983306258/locations/us-central1/trainingPipelines/8759625932366413824 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/934983306258/locations/us-central1/trainingPipelines/8759625932366413824 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "embedding_cols = list(pd.read_csv(DATA_DIR + 'embedding.csv').columns)\n",
    "embedding_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMLTabularTrainingJob projects/934983306258/locations/us-central1/trainingPipelines/8759625932366413824 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "num_embedding_cols = [i for i in embedding_cols if i not in ['provider', 'providerId']]\n",
    "embedding_column_specs = {column: \"numeric\" for column in num_embedding_cols}\n",
    "\n",
    "embedding_job = aiplatform.AutoMLTabularTrainingJob(\n",
    "    display_name=\"train-fraud-embeddings-automl\",\n",
    "    optimization_prediction_type=\"classification\",\n",
    "    optimization_objective=\"minimize-log-loss\",\n",
    "    column_specs=embedding_column_specs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/7088579364379426816?project=934983306258\n",
      "AutoMLTabularTrainingJob projects/934983306258/locations/us-central1/trainingPipelines/7088579364379426816 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/934983306258/locations/us-central1/trainingPipelines/7088579364379426816 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/934983306258/locations/us-central1/trainingPipelines/8759625932366413824 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/934983306258/locations/us-central1/trainingPipelines/7088579364379426816 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/934983306258/locations/us-central1/trainingPipelines/7088579364379426816 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/934983306258/locations/us-central1/trainingPipelines/7088579364379426816 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/934983306258/locations/us-central1/trainingPipelines/8759625932366413824 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/934983306258/locations/us-central1/trainingPipelines/7088579364379426816 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "embedding_model = embedding_job.run(\n",
    "    dataset=embedding_dataset,\n",
    "    target_column=\"potentialFraudInd\",\n",
    "    training_fraction_split=0.6,\n",
    "    validation_fraction_split=0.2,\n",
    "    test_fraction_split=0.2,\n",
    "    model_display_name=\"train-fraud-embeddings-automl\",\n",
    "    disable_early_stopping=False,\n",
    "    budget_milli_node_hours=1000,\n",
    "    sync = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 milli node hours, or one node hour, is the minimum budget that Vertex AI allows. However, Vertex AI isn't respecting that budget currently. This job will probably run for two and a half hours.\n",
    "\n",
    "We're going to move on while that runs. You can check on the job later in the Google Cloud Console to see the results. There's a link to the specific job in the output of the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Once completed, you can start comparing the training results of both of your models. My results look like below.\n",
    "I could see a ~10% improved F1 score and precision with my embedding model than the raw one.\n",
    "\n",
    "![Metrics](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/emb_vs_raw-metrics.png)\n",
    "\n",
    "![Metrics1](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/emb_vs_raw-metrics1.png)\n",
    "\n",
    "This the feature importance in both the models. As you can see embeddings could capture more meaningful features by relationships than the raw ones.\n",
    "\n",
    "![Feature Comparison](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/emb_vs_raw-features.png)\n",
    "\n",
    "Finally, this is the Confusion Matrix of the two models. The embedding algorithms has lesser false positives.\n",
    "\n",
    "![Confusion Matrix](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/emb_vs_raw-confusion.png)\n",
    "\n",
    "\n",
    "# Conclusion\n",
    "Vertex AI made our job simpler by taking care of lots of overheads like hyper parameter tuning, feature importance etc. Once you find your best model using Vertex AI, you can also export the features like embeddings generated using GDS to Vertex AI Feature Store, deploy your model endpoints and start doing some predictions. \n",
    "\n",
    "Neo4j GDS has more than 70 algorithms in the toolbox which can help you do Graph Data Science in a memory optimised platform. While we covered only FastRP embedding algorithm here, there are few more like GraphSAGE, Node2Vec, HashGNN etc. The models we tested out could be improved more and can include both raw and embedding features. We will leave it to you to try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
  },
  "instance_type": "ml.t3.medium",
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
