{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rQ6G65n6OxV"
   },
   "source": [
    "# Create Embedding\n",
    "In this notebook, we'll connect to a Neo4j instance.  We'll load data based on a schema and compute graph embeddings.  The notebook exports that data to pandas and then writes them to Cloud Storage as CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MwTYwKk6OxX"
   },
   "source": [
    "## Using the Neo4j API\n",
    "Let's connect to our Neo4j deployment.  First off, install the Neo4j Graph Data Science package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15528,
     "status": "ok",
     "timestamp": 1681110797351,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "id": "FT0KaLYj6OxX",
    "outputId": "0298985b-0f45-4321-d94d-6da99305725c"
   },
   "outputs": [],
   "source": [
    "!pip install graphdatascience --quiet\n",
    "!pip install --quiet google-cloud-storage\n",
    "!pip install --quiet google.cloud.aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFokFbiL6OxY"
   },
   "source": [
    "Now, you're going to need the connection string and credentials from the deployment you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681109793559,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "gather": {
     "logged": 1669344803314
    },
    "id": "P41l_P4zzSqF"
   },
   "outputs": [],
   "source": [
    "# Edit these variables!\n",
    "DB_URL = '' #'neo4j+s://URL.databases.neo4j.io'\n",
    "DB_PASS = ''\n",
    "\n",
    "# You can leave this default\n",
    "DB_USER = 'neo4j'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create GDS connection object using the variables defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2309,
     "status": "ok",
     "timestamp": 1681109795865,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "gather": {
     "logged": 1669344806183
    },
    "id": "8lUkSvmozSqF"
   },
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "gds = GraphDataScience(DB_URL, auth=(DB_USER, DB_PASS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjzOZkVD8uLe",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Explore & Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are going to use is from a public available [Kaggle dataset](https://www.kaggle.com/datasets/rohitrox/healthcare-provider-fraud-detection-analysis).  These are healthcare expense claims with anonymised beneficiaries, claims and providers.  We've filtered the data and cleaned up the datasets. The cleaned data can be downloaded [here](https://storage.googleapis.com/neo4j-datasets/insurance-claim/data.csv)\n",
    "\n",
    "We will predict the potentially fraudulent providers based on the claims filed by them. We will use a GDS embedding algorithm to chart out Fraudulent patterns in the provider's claims to understand the future behaviour of providers.\n",
    "\n",
    "The dataset has\n",
    "\n",
    "- **Inpatient Data**: \n",
    "Contains claims filed for those patients who are admitted in the hospitals. It also provides additional details like their admission and discharge dates and admit and diagnosis code.\n",
    "- **Outpatient Data**\n",
    "- **Beneficiary Details Data**: \n",
    "Contains beneficiary KYC details like health conditions,regioregion they belong to etc. \n",
    "\n",
    "\n",
    "Before loading data into any Database, we usually have to come up with a schema and implement it on the Database. Graph Data Modelling is an important step with Neo4j and you define it based on the questions you would like to ask on the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested, you can explore the data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Let\n",
    "raw_df = pd.read_csv('https://storage.googleapis.com/neo4j-datasets/insurance-claim/data.csv', \n",
    "                     index_col=False, dtype='unicode', parse_dates=['claim_start_dt', 'claim_end_dt', 'admission_dt', 'discharge_dt'])\n",
    "raw_df.deductible_amt_paid = raw_df.deductible_amt_paid.astype(float)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go with the following schema as our questions are more focussed around the relationships between claims, providers, physicians and the diagnoses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILyN0cr18uLe",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Create Constraints\n",
    "In order to ensure uniqueness of nodes, lets create some constraints. This will ensure that no duplicate nodes are created and speed up the CSV loading process, especially if we want to use `MERGE` statements - as MERGE statement creates new nodes only if they don't exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1669263867155
    },
    "id": "s00ivuUo8uLe",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputId": "3d4af302-b77b-419c-f441-a0546bf02bf9"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "node_labels = ['Beneficiary', 'County', 'State', 'Claim', 'DiagnosisGroup', 'AdmitDiagnosis', 'Physician', 'Provider', 'Diagnosis', 'Procedure']\n",
    "\n",
    "def to_snake_case(s: str) -> str:\n",
    "    return re.sub(r'(?<!^)(?=[A-Z])', '_', s).lower()\n",
    "\n",
    "for node_label in node_labels:\n",
    "    gds.run_cypher(f'CREATE CONSTRAINT {to_snake_case(node_label) + \"_node_key\"} IF NOT EXISTS FOR (n:{node_label}) REQUIRE n.uid IS NODE KEY;')\n",
    "\n",
    "# Unlike above nodes, Condition  will use a \"name\" property as a unique key.\n",
    "gds.run_cypher(f'CREATE CONSTRAINT condition_node_key IF NOT EXISTS FOR (n:Condition) REQUIRE n.name IS NODE KEY;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2xwss1p8uLf",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Load Data\n",
    "\n",
    "Now, we're going to take data from the Google Cloud Storage bucket and import it into Neo4j.  There are a few different ways to do this.  We'll do with a naive LOAD CSV statements via the GDS Python API.  \n",
    "\n",
    "The Neo4j [Data Importer](https://data-importer.neo4j.io/) is another option.  It's a great graphical way to import data.  However, the LOAD CSV option we're using makes it really easy to pull directly from Cloud Storage, so is probably a better choice for what we need.\n",
    "\n",
    "Lets start creating the `Beneficiary`, `Claim`, `Provider`, `County` and `State` nodes first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1669263891382
    },
    "id": "LOdBOBuI8uLf",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputId": "e6190d56-2a46-4c99-d1ff-52afd2a33d3b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def chunks(xs, n=30_000):\n",
    "    n = max(1, n)\n",
    "    return [xs[i:i + n] for i in range(0, len(xs), n)]\n",
    "\n",
    "records = raw_df.to_dict('records')\n",
    "print('======  loading Beneficiary, Provider, Country, State, and Claim nodes  ======')\n",
    "\n",
    "cumulative_count = 0\n",
    "for recs in chunks(records):\n",
    "    gds.run_cypher(\n",
    "      \"\"\"\n",
    "        UNWIND $records AS row\n",
    "\n",
    "        MERGE (bene:Beneficiary {uid: row.bene_id})\n",
    "        ON CREATE SET\n",
    "            bene.dob = row.dob,\n",
    "            bene.gender = row.gender,\n",
    "            bene.race = row.race,\n",
    "            bene.ipAnnualReimbursementAmt = row.ip_annual_reimbursement_amt,\n",
    "            bene.opAnnualReimbursementAmt = row.op_annual_reimbursement_amt,\n",
    "            bene.ipAnnualDeductibleAmt = row.ip_annual_deductible_amt,\n",
    "            bene.opAnnualDeductibleAmt = row.op_annual_deductible_amt,\n",
    "            bene.partACovMonths = row.num_of_months_part_a_cov,\n",
    "            bene.partBCovMonths = row.num_of_months_part_b_Cov,\n",
    "            bene.dod = row.dod\n",
    "\n",
    "        MERGE (provider:Provider {uid: row.provider})\n",
    "\n",
    "        MERGE (county:County {uid: row.county})\n",
    "\n",
    "        MERGE (state:State {uid: row.state})\n",
    "\n",
    "        MERGE (claim:Claim {uid: row.claim_id})\n",
    "            SET claim.startDate = row.claim_start_dt,\n",
    "                claim.endDate = row.claim_end_dt,\n",
    "                claim.reimbursedAmt = row.claim_amt_reimbursed,\n",
    "                claim.isFraud = row.is_fraud,\n",
    "                claim.dischargeDate = row.discharge_dt,\n",
    "                claim.admitDate = row.admission_dt,\n",
    "                claim.deductibleAmtPaid = row.deductible_amt_paid\n",
    "      \"\"\"\n",
    "    , params={'records': recs})\n",
    "    cumulative_count += len(recs)\n",
    "    print(f'Loaded {cumulative_count:,} of {len(records):,} records')\n",
    "print(f'Loading Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the schema we agreed upon earlier, lets start to connect the ndoes we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = raw_df[['bene_id', 'claim_id', 'provider', 'county', 'state']].to_dict('records')\n",
    "\n",
    "result = gds.run_cypher(\n",
    "  \"\"\"\n",
    "    UNWIND $records AS row\n",
    "    MATCH (bene:Beneficiary {uid: row.bene_id})\n",
    "    MATCH (claim:Claim {uid: row.claim_id})\n",
    "    MATCH (provider:Provider {uid: row.provider})\n",
    "    MATCH (county:County {uid: row.county})\n",
    "    MATCH (state:State {uid: row.state})\n",
    "\n",
    "    MERGE (county)<-[:LOCATED_AT]-(bene)\n",
    "    MERGE (bene)-[:FILED_CLAIM]->(claim)-[:PROVIDED_BY]->(provider)\n",
    "    MERGE (state)<-[:PART_OF]-(county)\n",
    "  \"\"\"\n",
    "    , params={'records': records})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to create the `Physician` nodes and relate them to Claims and Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a reshaped physician dataframe to make loading more efficient\n",
    "physician_role_map = {'operating_physician':'OPERATED_BY', 'attending_physician':'ATTENDED_BY', 'other_physician':'ALSO_ATTENDED_BY'}\n",
    "physician_dfs = []\n",
    "for col, role in physician_role_map.items():\n",
    "    temp_df = raw_df[['claim_id', 'provider', col]].rename(columns={col: 'physician_id'}).dropna()\n",
    "    temp_df['physician_role'] = role\n",
    "    physician_dfs.append(temp_df)\n",
    "physician_df = pd.concat(physician_dfs)\n",
    "physician_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load Physician nodes\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $physicianIds AS physicianId\n",
    "      MERGE (physician:Physician {uid: physicianId})\n",
    "    \"\"\"\n",
    "    , params={'physicianIds': physician_df.physician_id.drop_duplicates().tolist()})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load Physician worked for provider relationship\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $records AS row\n",
    "      MATCH (provider:Provider {uid: row.provider})\n",
    "      MATCH (physician:Physician {uid: row.physician_id})\n",
    "      MERGE (provider)<-[:WORKS_FOR]-(physician)\n",
    "    \"\"\"\n",
    "    , params={'records': physician_df[['provider','physician_id']].drop_duplicates().to_dict('records')})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load Physician claim relationships\n",
    "for role in physician_role_map.values():\n",
    "    print(f'Loading {role} relationships...')\n",
    "    gds.run_cypher(\n",
    "        f\"\"\"\n",
    "          UNWIND $records AS row\n",
    "          MATCH (physician:Physician {{uid: row.physician_id}})\n",
    "          MATCH (claim:Claim {{uid: row.claim_id}})\n",
    "          MERGE (physician)<-[:{role}]-(claim)\n",
    "        \"\"\"\n",
    "        , params={'records': physician_df.loc[physician_df.physician_role == role, ['claim_id','physician_id']].to_dict('records')})\n",
    "print('Loading complete')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then create `AdmitDiagnosis` and `DiagnosisGroup` nodes and relate them to Claims and Providers as well"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#load admin diagnosis codes\n",
    "print(f'Loading AdmitDiagnosis nodes...')\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $claim_admit_diagnosis_codes as claim_admit_diagnosis_code\n",
    "      MERGE (admitDiagnosis:AdmitDiagnosis {uid: claim_admit_diagnosis_code})\n",
    "    \"\"\"\n",
    "    , params={'claim_admit_diagnosis_codes': raw_df.claim_admit_diagnosis_code.dropna().drop_duplicates().to_list()})\n",
    "\n",
    "#load admin diagnosis relationships\n",
    "print(f'Loading HAS_ADMIT_DIAGNOSIS relationships...')\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $records AS row\n",
    "      MATCH (claim:Claim {uid: row.claim_id})\n",
    "      MATCH (admitDiagnosis:AdmitDiagnosis {uid: row.claim_admit_diagnosis_code})\n",
    "      MERGE (claim)-[:HAS_ADMIT_DIAGNOSIS]->(admitDiagnosis)\n",
    "    \"\"\"\n",
    "    , params={'records': raw_df[['claim_id','claim_admit_diagnosis_code']].dropna().to_dict('records')})\n",
    "print('Loading complete')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#load admin diagnosis codes\n",
    "print(f'Loading DiagnosisGroup nodes...')\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $diag_group_codes as diag_group_code\n",
    "      MERGE (diagnosisGroup:DiagnosisGroup {uid: diag_group_code})\n",
    "    \"\"\"\n",
    "    , params={'diag_group_codes': raw_df.diag_group_code.dropna().drop_duplicates().to_list()})\n",
    "\n",
    "#load admin diagnosis relationships\n",
    "print(f'Loading HAS_DIAGNOSIS_GROUP relationships...')\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $records AS row\n",
    "      MATCH (claim:Claim {uid: row.claim_id})\n",
    "      MATCH (diagnosisGroup:DiagnosisGroup {uid: row.diag_group_code})\n",
    "      MERGE (claim)-[:HAS_DIAGNOSIS_GROUP]->(diagnosisGroup)\n",
    "    \"\"\"\n",
    "    , params={'records': raw_df[['claim_id','diag_group_code']].dropna().to_dict('records')})\n",
    "print('Loading complete')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the schema, Claims are related to procedures. Let deal with those nodes & relationships now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a reshaped procedure dataframe to make loading more efficient\n",
    "proc_cols = [col for col in raw_df.columns if 'claim_procedure_code' in col]\n",
    "proc_df = pd.wide_to_long(raw_df[proc_cols  + ['claim_id']], stubnames='claim_procedure_code', i='claim_id', j='proc', sep='_').dropna().reset_index()\n",
    "proc_df.claim_procedure_code = pd.to_numeric(proc_df.claim_procedure_code).astype('Int64')\n",
    "proc_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load procedure nodes\n",
    "print(f'Loading Procedure nodes...')\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $claim_procedure_codes as claim_procedure_code\n",
    "      MERGE (proc:Procedure {uid: claim_procedure_code})\n",
    "    \"\"\"\n",
    "    , params={'claim_procedure_codes': proc_df.claim_procedure_code.drop_duplicates().to_list()})\n",
    "\n",
    "#load procedure - claim relationships\n",
    "print(f'Loading HAS_PROCEDURE relationships...')\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $records AS row\n",
    "      MATCH (claim:Claim {uid: row.claim_id})\n",
    "      MATCH (proc:Procedure {uid: row.claim_procedure_code})\n",
    "      MERGE (claim)-[:HAS_PROCEDURE]->(proc)\n",
    "    \"\"\"\n",
    "    , params={'records': proc_df.to_dict('records')})\n",
    "print('Loading complete')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As per the schema, Claims also have diagnoses. Let deal with those nodes & relationships here too"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a reshaped claim diagnosis dataframe to make loading more efficient\n",
    "diag_cols = [col for col in raw_df.columns if 'claim_diag_code' in col]\n",
    "claim_diag_df = pd.wide_to_long(raw_df[diag_cols  + ['claim_id']], stubnames='claim_diag_code', i='claim_id', j='claim_number', sep='_').dropna().reset_index()\n",
    "claim_diag_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load diagnosis claim nodes\n",
    "print(f'Loading Diagnosis nodes...')\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $claim_diag_code as claim_diag_code\n",
    "      MERGE (diag:Diagnosis {uid: claim_diag_code})\n",
    "    \"\"\"\n",
    "    , params={'claim_diag_code': claim_diag_df.claim_diag_code.drop_duplicates().to_list()})\n",
    "\n",
    "#load diagnosis - claim relationships\n",
    "print(f'Loading HAS_DIAGNOSIS relationships...')\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $records AS row\n",
    "      MATCH (claim:Claim {uid: row.claim_id})\n",
    "      MATCH (diag:Diagnosis {uid: row.claim_diag_code})\n",
    "      MERGE (claim)-[:HAS_DIAGNOSIS]->(diag)\n",
    "    \"\"\"\n",
    "    , params={'records': claim_diag_df.to_dict('records')})\n",
    "print('Loading complete')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets connect our Benificiaries (or) patients with diseases they suffer from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a reshaped chronic condition dataframe to make loading more efficient\n",
    "cond_cols = [col for col in raw_df.columns if 'chronic_cond' in col]\n",
    "cond_df = (pd.wide_to_long(raw_df[cond_cols  + ['bene_id']].drop_duplicates(), stubnames='chronic_cond', i='bene_id', j='condition', sep='_', suffix='\\D+')\n",
    "           .reset_index().query('chronic_cond == \"1\"').drop(columns='chronic_cond'))\n",
    "cond_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load condition nodes\n",
    "print(f'Loading Condition nodes...')\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $conditions as condition\n",
    "      MERGE (cond:Condition {name:condition})\n",
    "    \"\"\"\n",
    "    , params={'conditions': cond_df.condition.drop_duplicates().to_list()})\n",
    "\n",
    "#load condition - beneficiary relationships\n",
    "print(f'Loading HAS_CHRONIC relationships...')\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $records AS row\n",
    "      MATCH (bene:Beneficiary {uid: row.bene_id})\n",
    "      MATCH (cond:Condition {name:row.condition})\n",
    "      MERGE (bene)-[:HAS_CHRONIC]->(cond)\n",
    "    \"\"\"\n",
    "    , params={'records': cond_df.to_dict('records')})\n",
    "print('Loading complete')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load renal disease indicator. Unlike above this isn't necessarily associated with a chronic condition\n",
    "gds.run_cypher('MERGE (cond:Condition {name:\"renaldisease (from indicator)\"})')\n",
    "\n",
    "#load renal disease - beneficiary relationships\n",
    "print(f'Loading HAS_DISEASE relationships...')\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "      UNWIND $bene_ids AS bene_id\n",
    "      MATCH (bene:Beneficiary {uid: bene_id})\n",
    "      MATCH (cond:Condition {name:\"renaldisease (from indicator)\"})\n",
    "      MERGE (bene)-[:HAS_DISEASE]->(cond)\n",
    "    \"\"\"\n",
    "    , params={'bene_ids': raw_df.loc[raw_df.renal_disease_indicator == '1', 'bene_id'].drop_duplicates().tolist()})\n",
    "print('Loading complete')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a breakdown of high-level counts by labels and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total node counts\n",
    "gds.run_cypher(\"\"\"\n",
    "    CALL apoc.meta.stats()\n",
    "    YIELD labels\n",
    "    UNWIND keys(labels) AS nodeLabel\n",
    "    RETURN nodeLabel, labels[nodeLabel] AS nodeCount\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total relationship counts\n",
    "gds.run_cypher(\"\"\"\n",
    "    CALL apoc.meta.stats()\n",
    "    YIELD relTypesCount\n",
    "    UNWIND keys(relTypesCount) AS relationshipType\n",
    "    RETURN relationshipType, relTypesCount[relationshipType] AS relationshipCount\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtJy4eO_zSqF"
   },
   "source": [
    "## Graph Data Science\n",
    "We got the data inside our Database! Let's do some Graph Data Science. This is how a typical GDS workflow looks like inside Neo4j\n",
    "\n",
    "![GDS Workflow](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/gds_workflow.png)\n",
    "\n",
    "As first step, we're going to use Neo4j Graph Data Science to create an in memory graph represtation of the data.  We'll enhance that representation with features we engineer using a graph embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [
    {
     "data": {
      "text/plain": "nodeProjection            {'Condition': {'label': 'Condition', 'properti...\nrelationshipProjection    {'HAS_DIAGNOSIS': {'orientation': 'UNDIRECTED'...\ngraphName                                                        projection\nnodeCount                                                            167271\nrelationshipCount                                                   2105376\nprojectMillis                                                           297\nName: 0, dtype: object"
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g, _ = gds.graph.project('projection',\n",
    "                         ['Beneficiary','Condition','County','State','Claim','DiagnosisGroup','AdmitDiagnosis',\n",
    "                          'Physician','Provider','Diagnosis','Procedure'],\n",
    "                         {\n",
    "                             'LOCATED_AT': {'orientation': 'UNDIRECTED'},\n",
    "                             'FILED_CLAIM': {'orientation': 'UNDIRECTED'},\n",
    "                             'PROVIDED_BY': {'orientation': 'UNDIRECTED'},\n",
    "                             'PART_OF': {'orientation': 'UNDIRECTED'},\n",
    "                             'WORKS_FOR': {'orientation': 'UNDIRECTED'},\n",
    "                             'ATTENDED_BY': {'orientation': 'UNDIRECTED'},\n",
    "                             'OPERATED_BY': {'orientation': 'UNDIRECTED'},\n",
    "                             'ALSO_ATTENDED_BY': {'orientation': 'UNDIRECTED'},\n",
    "                             'HAS_ADMIT_DIAGNOSIS': {'orientation': 'UNDIRECTED'},\n",
    "                             'HAS_DIAGNOSIS_GROUP': {'orientation': 'UNDIRECTED'},\n",
    "                             'HAS_PROCEDURE': {'orientation': 'UNDIRECTED'},\n",
    "                             'HAS_DIAGNOSIS': {'orientation': 'UNDIRECTED'},\n",
    "                             'HAS_CHRONIC': {'orientation': 'UNDIRECTED'},\n",
    "                             'HAS_DISEASE': {'orientation': 'UNDIRECTED'}\n",
    "                         })\n",
    "_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiwL552u6Oxb"
   },
   "source": [
    "If you get an error saying the graph already exists, that's probably because you ran this code before. You can destroy it using this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1681109905724,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "gather": {
     "logged": 1669263902233
    },
    "id": "EPZIIIJc6Oxb",
    "outputId": "a4b51e53-9b21-4f0f-fe6a-9a41fb4481cc"
   },
   "outputs": [],
   "source": [
    "# if gds.graph.exists('projection').exists:\n",
    "#    gds.graph.get('projection').drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zG1novOj6Oxb"
   },
   "source": [
    "Now, let's list the details of the graph to make sure the projection was created as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1681109923007,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "gather": {
     "logged": 1669344842885
    },
    "id": "yyaw5itE6Oxb",
    "outputId": "0e957f92-fe36-40d3-b658-fc8de5ffb369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node count: 167271\n",
      "relationship count: 2105376\n",
      "node labels: ['Condition', 'State', 'DiagnosisGroup', 'Physician', 'Procedure', 'Diagnosis', 'AdmitDiagnosis', 'County', 'Claim', 'Beneficiary', 'Provider']\n",
      "relationship types: ['HAS_DIAGNOSIS', 'HAS_PROCEDURE', 'HAS_DIAGNOSIS_GROUP', 'OPERATED_BY', 'PART_OF', 'PROVIDED_BY', 'ATTENDED_BY', 'LOCATED_AT', 'HAS_DISEASE', 'HAS_ADMIT_DIAGNOSIS', 'FILED_CLAIM', 'ALSO_ATTENDED_BY', 'WORKS_FOR', 'HAS_CHRONIC']\n"
     ]
    }
   ],
   "source": [
    "print(f\"node count: {g.node_count()}\")\n",
    "print(f\"relationship count: {g.relationship_count()}\")\n",
    "print(f\"node labels: {g.node_labels()}\")\n",
    "print(f\"relationship types: {g.relationship_types()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEQAChAa6Oxb"
   },
   "source": [
    "Now we can generate an embedding from that graph. This is a new feature we can use in our predictions. We're using FastRP, which is a more full featured and higher performance of Node2Vec. You can learn more about that [here](https://neo4j.com/docs/graph-data-science/current/algorithms/fastrp/).\n",
    "\n",
    "There are a bunch of parameters we could adjust in this.  One of the most obvious is the embeddingDimension.  The documentation covers many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1681109936445,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "gather": {
     "logged": 1669344853127
    },
    "id": "qLFxuPb66Oxc",
    "outputId": "8ead5add-039b-4749-db21-ae1cb0595ae1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "nodePropertiesWritten                                               167271\nmutateMillis                                                             0\nnodeCount                                                           167271\npreProcessingMillis                                                      0\ncomputeMillis                                                          369\nconfiguration            {'nodeSelfInfluence': 0, 'propertyRatio': 0.0,...\nName: 0, dtype: object"
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.fastRP.mutate(g, embeddingDimension=32, randomSeed=1, mutateProperty='embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRpgM-NV6Oxc"
   },
   "source": [
    "That creates an embedding for each node type.  However, we only want the embedding on the nodes of type holding.\n",
    "\n",
    "We're going to take the embedding from our projection and write it to the holding nodes in the underlying database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 1634,
     "status": "ok",
     "timestamp": 1681109940975,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "gather": {
     "logged": 1669344860116
    },
    "id": "3dBS16zD6Oxc",
    "outputId": "9a8be315-e872-4b79-99ea-25a0dacb7379",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "176"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = gds.graph.writeNodeProperties(g, ['embedding'], ['Claim'])\n",
    "result.writeMillis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               id                                          embedding target\n0       CLM110011  [-0.3046455681324005, -0.48370498418807983, -0...      1\n1       CLM110030  [0.09364302456378937, 0.013624608516693115, -0...      1\n2       CLM110031  [-0.2793812155723572, -0.6372988820075989, 0.0...      1\n3       CLM110038  [-0.07748548686504364, -0.25101712346076965, 0...      0\n4       CLM110040  [-0.362213134765625, -0.22709669172763824, -0....      1\n...           ...                                                ...    ...\n100075   CLM82009  [0.04165990650653839, -0.6641069650650024, -0....      1\n100076   CLM82013  [-0.0238773375749588, -0.6360070109367371, -0....      1\n100077   CLM82218  [0.12991547584533691, -0.24101734161376953, 0....      1\n100078   CLM82303  [-0.054207198321819305, -0.005985379219055176,...      1\n100079   CLM82313  [-0.09070680290460587, -0.28521448373794556, 0...      1\n\n[100080 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>embedding</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CLM110011</td>\n      <td>[-0.3046455681324005, -0.48370498418807983, -0...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CLM110030</td>\n      <td>[0.09364302456378937, 0.013624608516693115, -0...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CLM110031</td>\n      <td>[-0.2793812155723572, -0.6372988820075989, 0.0...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CLM110038</td>\n      <td>[-0.07748548686504364, -0.25101712346076965, 0...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CLM110040</td>\n      <td>[-0.362213134765625, -0.22709669172763824, -0....</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100075</th>\n      <td>CLM82009</td>\n      <td>[0.04165990650653839, -0.6641069650650024, -0....</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>100076</th>\n      <td>CLM82013</td>\n      <td>[-0.0238773375749588, -0.6360070109367371, -0....</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>100077</th>\n      <td>CLM82218</td>\n      <td>[0.12991547584533691, -0.24101734161376953, 0....</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>100078</th>\n      <td>CLM82303</td>\n      <td>[-0.054207198321819305, -0.005985379219055176,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>100079</th>\n      <td>CLM82313</td>\n      <td>[-0.09070680290460587, -0.28521448373794556, 0...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100080 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = gds.run_cypher(\n",
    "  \"\"\" \n",
    "    MATCH (claim:Claim)\n",
    "    RETURN claim.uid as id, claim.embedding as embedding, claim.isFraud as target\n",
    "  \"\"\"\n",
    ")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we just did\n",
    "\n",
    "![embeddings](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/what_are_embeddings.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQ5vwvnl8uLh"
   },
   "source": [
    "# Export Embeddings\n",
    "Now we're going to reformat the query output so that the embeddings can be fed in to a Vertex AI Auto ML pipeline. Note that we are exporting only embeddings and all the other features are intentionally left out. This is to showcase how powerful these vectors are!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3esUO8s6Oxc"
   },
   "source": [
    "Note that the embedding row is an array. To make this dataset more consumable, we should flatten that out into multiple individual features: embedding_0, embedding_1, ... embedding_n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "executionInfo": {
     "elapsed": 811,
     "status": "ok",
     "timestamp": 1681109976089,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "gather": {
     "logged": 1669344969701
    },
    "id": "-i0_txCB6Oxc",
    "outputId": "77406878-d2d4-4960-8e62-5f4657cb08a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               id target  embedding_0  embedding_1  embedding_2  embedding_3  \\\n0       CLM110011      1    -0.304646    -0.483705    -0.357203    -0.302861   \n1       CLM110030      1     0.093643     0.013625    -0.479409     0.057462   \n2       CLM110031      1    -0.279381    -0.637299     0.007481     0.098682   \n3       CLM110038      0    -0.077485    -0.251017     0.180458     0.633138   \n4       CLM110040      1    -0.362213    -0.227097    -0.192352     0.089990   \n...           ...    ...          ...          ...          ...          ...   \n100075   CLM82009      1     0.041660    -0.664107    -0.249968     0.591536   \n100076   CLM82013      1    -0.023877    -0.636007    -0.467070     0.062771   \n100077   CLM82218      1     0.129915    -0.241017     0.205425     0.469056   \n100078   CLM82303      1    -0.054207    -0.005985    -0.224177     0.502715   \n100079   CLM82313      1    -0.090707    -0.285214     0.200254     0.032927   \n\n        embedding_4  embedding_5  embedding_6  embedding_7  ...  embedding_22  \\\n0          0.100711     0.106431     0.021861    -0.274979  ...     -0.328284   \n1         -0.219684    -0.084565    -0.375288     0.117837  ...     -0.214706   \n2          0.481290    -0.065113     0.280593    -0.153458  ...     -0.092117   \n3          0.317620     0.253783    -0.156635     0.126405  ...      0.028823   \n4         -0.015110    -0.441792    -0.021205     0.137845  ...     -0.407148   \n...             ...          ...          ...          ...  ...           ...   \n100075    -0.208832     0.183202    -0.469215     0.017440  ...      0.051976   \n100076     0.472643    -0.110822    -0.589941    -0.016301  ...      0.388619   \n100077     0.049277    -0.411168    -0.260873    -0.494940  ...      0.109164   \n100078     0.030636     0.002026    -0.081165    -0.202303  ...      0.131457   \n100079    -0.316212    -0.147741    -0.336941    -0.574437  ...      0.135123   \n\n        embedding_23  embedding_24  embedding_25  embedding_26  embedding_27  \\\n0           0.077383      0.046006     -0.056047     -0.129007     -0.007562   \n1           0.268210      0.220086      0.080279     -0.077321      0.318584   \n2           0.524109      0.339914     -0.375202     -0.041442      0.231110   \n3           0.170212      0.731474     -0.216520      0.031700      0.159313   \n4          -0.137814     -0.271657     -0.010866     -0.178115      0.233506   \n...              ...           ...           ...           ...           ...   \n100075      0.416909      0.158655      0.014122     -0.190709      0.159962   \n100076     -0.045963      0.019847     -0.097595     -0.222180     -0.005405   \n100077      0.040084      0.152925      0.002155     -0.213440      0.136800   \n100078     -0.247158      0.555261      0.253013      0.278891      0.391433   \n100079      0.229310     -0.358200     -0.261134      0.120156     -0.250165   \n\n        embedding_28  embedding_29  embedding_30  embedding_31  \n0           0.271084      0.115958     -0.175314      0.513049  \n1           0.101539      0.018138      0.171507      0.077746  \n2           0.331119      0.129880      0.049741     -0.284475  \n3           0.425701      0.008861      0.292919     -0.360491  \n4           0.160516      0.396605     -0.001921      0.078454  \n...              ...           ...           ...           ...  \n100075      0.401225     -0.089189      0.109903     -0.005102  \n100076     -0.111435      0.218153      0.035548      0.387169  \n100077      0.433116      0.312274     -0.097761      0.267573  \n100078      0.137198     -0.133029      0.468623      0.033940  \n100079      0.440375     -0.064736     -0.080897      0.499186  \n\n[100080 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n      <th>embedding_0</th>\n      <th>embedding_1</th>\n      <th>embedding_2</th>\n      <th>embedding_3</th>\n      <th>embedding_4</th>\n      <th>embedding_5</th>\n      <th>embedding_6</th>\n      <th>embedding_7</th>\n      <th>...</th>\n      <th>embedding_22</th>\n      <th>embedding_23</th>\n      <th>embedding_24</th>\n      <th>embedding_25</th>\n      <th>embedding_26</th>\n      <th>embedding_27</th>\n      <th>embedding_28</th>\n      <th>embedding_29</th>\n      <th>embedding_30</th>\n      <th>embedding_31</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CLM110011</td>\n      <td>1</td>\n      <td>-0.304646</td>\n      <td>-0.483705</td>\n      <td>-0.357203</td>\n      <td>-0.302861</td>\n      <td>0.100711</td>\n      <td>0.106431</td>\n      <td>0.021861</td>\n      <td>-0.274979</td>\n      <td>...</td>\n      <td>-0.328284</td>\n      <td>0.077383</td>\n      <td>0.046006</td>\n      <td>-0.056047</td>\n      <td>-0.129007</td>\n      <td>-0.007562</td>\n      <td>0.271084</td>\n      <td>0.115958</td>\n      <td>-0.175314</td>\n      <td>0.513049</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CLM110030</td>\n      <td>1</td>\n      <td>0.093643</td>\n      <td>0.013625</td>\n      <td>-0.479409</td>\n      <td>0.057462</td>\n      <td>-0.219684</td>\n      <td>-0.084565</td>\n      <td>-0.375288</td>\n      <td>0.117837</td>\n      <td>...</td>\n      <td>-0.214706</td>\n      <td>0.268210</td>\n      <td>0.220086</td>\n      <td>0.080279</td>\n      <td>-0.077321</td>\n      <td>0.318584</td>\n      <td>0.101539</td>\n      <td>0.018138</td>\n      <td>0.171507</td>\n      <td>0.077746</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CLM110031</td>\n      <td>1</td>\n      <td>-0.279381</td>\n      <td>-0.637299</td>\n      <td>0.007481</td>\n      <td>0.098682</td>\n      <td>0.481290</td>\n      <td>-0.065113</td>\n      <td>0.280593</td>\n      <td>-0.153458</td>\n      <td>...</td>\n      <td>-0.092117</td>\n      <td>0.524109</td>\n      <td>0.339914</td>\n      <td>-0.375202</td>\n      <td>-0.041442</td>\n      <td>0.231110</td>\n      <td>0.331119</td>\n      <td>0.129880</td>\n      <td>0.049741</td>\n      <td>-0.284475</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CLM110038</td>\n      <td>0</td>\n      <td>-0.077485</td>\n      <td>-0.251017</td>\n      <td>0.180458</td>\n      <td>0.633138</td>\n      <td>0.317620</td>\n      <td>0.253783</td>\n      <td>-0.156635</td>\n      <td>0.126405</td>\n      <td>...</td>\n      <td>0.028823</td>\n      <td>0.170212</td>\n      <td>0.731474</td>\n      <td>-0.216520</td>\n      <td>0.031700</td>\n      <td>0.159313</td>\n      <td>0.425701</td>\n      <td>0.008861</td>\n      <td>0.292919</td>\n      <td>-0.360491</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CLM110040</td>\n      <td>1</td>\n      <td>-0.362213</td>\n      <td>-0.227097</td>\n      <td>-0.192352</td>\n      <td>0.089990</td>\n      <td>-0.015110</td>\n      <td>-0.441792</td>\n      <td>-0.021205</td>\n      <td>0.137845</td>\n      <td>...</td>\n      <td>-0.407148</td>\n      <td>-0.137814</td>\n      <td>-0.271657</td>\n      <td>-0.010866</td>\n      <td>-0.178115</td>\n      <td>0.233506</td>\n      <td>0.160516</td>\n      <td>0.396605</td>\n      <td>-0.001921</td>\n      <td>0.078454</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100075</th>\n      <td>CLM82009</td>\n      <td>1</td>\n      <td>0.041660</td>\n      <td>-0.664107</td>\n      <td>-0.249968</td>\n      <td>0.591536</td>\n      <td>-0.208832</td>\n      <td>0.183202</td>\n      <td>-0.469215</td>\n      <td>0.017440</td>\n      <td>...</td>\n      <td>0.051976</td>\n      <td>0.416909</td>\n      <td>0.158655</td>\n      <td>0.014122</td>\n      <td>-0.190709</td>\n      <td>0.159962</td>\n      <td>0.401225</td>\n      <td>-0.089189</td>\n      <td>0.109903</td>\n      <td>-0.005102</td>\n    </tr>\n    <tr>\n      <th>100076</th>\n      <td>CLM82013</td>\n      <td>1</td>\n      <td>-0.023877</td>\n      <td>-0.636007</td>\n      <td>-0.467070</td>\n      <td>0.062771</td>\n      <td>0.472643</td>\n      <td>-0.110822</td>\n      <td>-0.589941</td>\n      <td>-0.016301</td>\n      <td>...</td>\n      <td>0.388619</td>\n      <td>-0.045963</td>\n      <td>0.019847</td>\n      <td>-0.097595</td>\n      <td>-0.222180</td>\n      <td>-0.005405</td>\n      <td>-0.111435</td>\n      <td>0.218153</td>\n      <td>0.035548</td>\n      <td>0.387169</td>\n    </tr>\n    <tr>\n      <th>100077</th>\n      <td>CLM82218</td>\n      <td>1</td>\n      <td>0.129915</td>\n      <td>-0.241017</td>\n      <td>0.205425</td>\n      <td>0.469056</td>\n      <td>0.049277</td>\n      <td>-0.411168</td>\n      <td>-0.260873</td>\n      <td>-0.494940</td>\n      <td>...</td>\n      <td>0.109164</td>\n      <td>0.040084</td>\n      <td>0.152925</td>\n      <td>0.002155</td>\n      <td>-0.213440</td>\n      <td>0.136800</td>\n      <td>0.433116</td>\n      <td>0.312274</td>\n      <td>-0.097761</td>\n      <td>0.267573</td>\n    </tr>\n    <tr>\n      <th>100078</th>\n      <td>CLM82303</td>\n      <td>1</td>\n      <td>-0.054207</td>\n      <td>-0.005985</td>\n      <td>-0.224177</td>\n      <td>0.502715</td>\n      <td>0.030636</td>\n      <td>0.002026</td>\n      <td>-0.081165</td>\n      <td>-0.202303</td>\n      <td>...</td>\n      <td>0.131457</td>\n      <td>-0.247158</td>\n      <td>0.555261</td>\n      <td>0.253013</td>\n      <td>0.278891</td>\n      <td>0.391433</td>\n      <td>0.137198</td>\n      <td>-0.133029</td>\n      <td>0.468623</td>\n      <td>0.033940</td>\n    </tr>\n    <tr>\n      <th>100079</th>\n      <td>CLM82313</td>\n      <td>1</td>\n      <td>-0.090707</td>\n      <td>-0.285214</td>\n      <td>0.200254</td>\n      <td>0.032927</td>\n      <td>-0.316212</td>\n      <td>-0.147741</td>\n      <td>-0.336941</td>\n      <td>-0.574437</td>\n      <td>...</td>\n      <td>0.135123</td>\n      <td>0.229310</td>\n      <td>-0.358200</td>\n      <td>-0.261134</td>\n      <td>0.120156</td>\n      <td>-0.250165</td>\n      <td>0.440375</td>\n      <td>-0.064736</td>\n      <td>-0.080897</td>\n      <td>0.499186</td>\n    </tr>\n  </tbody>\n</table>\n<p>100080 rows × 34 columns</p>\n</div>"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df = pd.DataFrame(result_df['embedding'].values.tolist()).add_prefix(\"embedding_\")\n",
    "merged_df = result_df.drop(columns=['embedding']).merge(embedding_df, left_index=True, right_index=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are curious, visualize the embeddings as a t-SNE plot. It can look something like this:\n",
    "![embedding_viz](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/embeddings-tsne.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Zb7lH366Oxc"
   },
   "source": [
    "Now that we have the data formatted properly, let's write it as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "executionInfo": {
     "elapsed": 1711,
     "status": "ok",
     "timestamp": 1681109982494,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "gather": {
     "logged": 1669344975782
    },
    "id": "uLg34zlu6Oxc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "outdir = './data'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "data = merged_df.sample(frac=1).reset_index(drop=True)\n",
    "data.to_csv(os.path.join(outdir, 'embedding.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Azb1inEVAC7f"
   },
   "source": [
    "## Upload to Google Cloud Storage\n",
    "Now let's write the file to Google Cloud Storage so we can use it in our model.  To do so, we must set a few environment variables.\n",
    "\n",
    "Edit the REGION variable below.  You'll want to be sure it matches the region where your notebook is running.\n",
    "\n",
    "The STORAGE_BUCKET is the name of a new bucket.  It must be globally unique.  It also needs to be all lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1681112445207,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "id": "xsDqLTwk8uLi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Edit this variable!\n",
    "REGION = 'us-west1'\n",
    "shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "\n",
    "STORAGE_BUCKET = PROJECT_ID + '-fsi'\n",
    "STORAGE_BUCKET\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(STORAGE_BUCKET)\n",
    "if not bucket.exists:\n",
    "    bucket.create(location=REGION)\n",
    "\n",
    "blob = bucket.blob(os.path.join('insurance_fraud', 'embedding.csv'))\n",
    "blob.upload_from_filename(os.path.join(outdir, 'embedding.csv'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also export factorize the raw data without embeddings and run a similar Auto ML pipeline on Vertex AI. Then, lets compare the accuracy between the two!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "data": {
      "text/plain": "           bene_id         id claim_start_dt claim_end_dt  provider  \\\n0        BENE11002  CLM624349     2009-10-11   2009-10-11  PRV56011   \n1        BENE11004  CLM121801     2009-01-06   2009-01-06  PRV56011   \n2        BENE11004  CLM150998     2009-01-22   2009-01-22  PRV56011   \n3        BENE11004  CLM173224     2009-02-03   2009-02-03  PRV56011   \n4        BENE11004  CLM224741     2009-03-03   2009-03-03  PRV56011   \n...            ...        ...            ...          ...       ...   \n100075  BENE100433  CLM514796     2009-08-08   2009-08-09  PRV54895   \n100076  BENE100499  CLM237382     2009-03-09   2009-03-10  PRV54895   \n100077  BENE100499  CLM676967     2009-11-11   2009-11-11  PRV54895   \n100078  BENE100569  CLM602032     2009-09-27   2009-09-27  PRV54895   \n100079  BENE100677  CLM226299     2009-03-03   2009-03-03  PRV54895   \n\n       claim_amt_reimbursed attending_physician operating_physician  \\\n0                        30           PHY326117                 NaN   \n1                        40           PHY334319                 NaN   \n2                       200           PHY403831                 NaN   \n3                        20           PHY339887                 NaN   \n4                        40           PHY345721                 NaN   \n...                     ...                 ...                 ...   \n100075                   10           PHY382394                 NaN   \n100076                  400           PHY385898                 NaN   \n100077                   50           PHY385898                 NaN   \n100078                  500           PHY368638           PHY368638   \n100079                  200           PHY347629                 NaN   \n\n       other_physician  claim_diag_code_1  ...  chronic_cond_diabetes  \\\n0                  NaN                  1  ...                      1   \n1                  NaN                  2  ...                      0   \n2                  NaN                  3  ...                      0   \n3                  NaN                  4  ...                      0   \n4                  NaN                  5  ...                      0   \n...                ...                ...  ...                    ...   \n100075             NaN               1815  ...                      0   \n100076             NaN               1351  ...                      1   \n100077             NaN                915  ...                      1   \n100078             NaN                128  ...                      1   \n100079             NaN               2761  ...                      1   \n\n        chronic_cond_ischemicheart  chronic_cond_osteoporasis  \\\n0                                1                          1   \n1                                0                          0   \n2                                0                          0   \n3                                0                          0   \n4                                0                          0   \n...                            ...                        ...   \n100075                           0                          1   \n100076                           0                          0   \n100077                           0                          0   \n100078                           0                          1   \n100079                           1                          0   \n\n        chronic_cond_rheumatoidarthritis  chronic_cond_stroke  \\\n0                                      1                    1   \n1                                      0                    1   \n2                                      0                    1   \n3                                      0                    1   \n4                                      0                    1   \n...                                  ...                  ...   \n100075                                 1                    1   \n100076                                 1                    0   \n100077                                 1                    0   \n100078                                 1                    1   \n100079                                 1                    1   \n\n        ip_annual_reimbursement_amt  ip_annual_deductible_amt  \\\n0                                 0                         0   \n1                                 0                         0   \n2                                 0                         0   \n3                                 0                         0   \n4                                 0                         0   \n...                             ...                       ...   \n100075                            0                         0   \n100076                            0                         0   \n100077                            0                         0   \n100078                            0                         0   \n100079                            0                         0   \n\n        op_annual_reimbursement_amt  op_annual_deductible_amt  target  \n0                                30                        50       1  \n1                              1810                       760       1  \n2                              1810                       760       1  \n3                              1810                       760       1  \n4                              1810                       760       1  \n...                             ...                       ...     ...  \n100075                         1630                       350       1  \n100076                         3870                       970       1  \n100077                         3870                       970       1  \n100078                         1000                       700       1  \n100079                          820                       280       1  \n\n[100080 rows x 55 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bene_id</th>\n      <th>id</th>\n      <th>claim_start_dt</th>\n      <th>claim_end_dt</th>\n      <th>provider</th>\n      <th>claim_amt_reimbursed</th>\n      <th>attending_physician</th>\n      <th>operating_physician</th>\n      <th>other_physician</th>\n      <th>claim_diag_code_1</th>\n      <th>...</th>\n      <th>chronic_cond_diabetes</th>\n      <th>chronic_cond_ischemicheart</th>\n      <th>chronic_cond_osteoporasis</th>\n      <th>chronic_cond_rheumatoidarthritis</th>\n      <th>chronic_cond_stroke</th>\n      <th>ip_annual_reimbursement_amt</th>\n      <th>ip_annual_deductible_amt</th>\n      <th>op_annual_reimbursement_amt</th>\n      <th>op_annual_deductible_amt</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BENE11002</td>\n      <td>CLM624349</td>\n      <td>2009-10-11</td>\n      <td>2009-10-11</td>\n      <td>PRV56011</td>\n      <td>30</td>\n      <td>PHY326117</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BENE11004</td>\n      <td>CLM121801</td>\n      <td>2009-01-06</td>\n      <td>2009-01-06</td>\n      <td>PRV56011</td>\n      <td>40</td>\n      <td>PHY334319</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1810</td>\n      <td>760</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BENE11004</td>\n      <td>CLM150998</td>\n      <td>2009-01-22</td>\n      <td>2009-01-22</td>\n      <td>PRV56011</td>\n      <td>200</td>\n      <td>PHY403831</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1810</td>\n      <td>760</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BENE11004</td>\n      <td>CLM173224</td>\n      <td>2009-02-03</td>\n      <td>2009-02-03</td>\n      <td>PRV56011</td>\n      <td>20</td>\n      <td>PHY339887</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1810</td>\n      <td>760</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BENE11004</td>\n      <td>CLM224741</td>\n      <td>2009-03-03</td>\n      <td>2009-03-03</td>\n      <td>PRV56011</td>\n      <td>40</td>\n      <td>PHY345721</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1810</td>\n      <td>760</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100075</th>\n      <td>BENE100433</td>\n      <td>CLM514796</td>\n      <td>2009-08-08</td>\n      <td>2009-08-09</td>\n      <td>PRV54895</td>\n      <td>10</td>\n      <td>PHY382394</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1815</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1630</td>\n      <td>350</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>100076</th>\n      <td>BENE100499</td>\n      <td>CLM237382</td>\n      <td>2009-03-09</td>\n      <td>2009-03-10</td>\n      <td>PRV54895</td>\n      <td>400</td>\n      <td>PHY385898</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1351</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3870</td>\n      <td>970</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>100077</th>\n      <td>BENE100499</td>\n      <td>CLM676967</td>\n      <td>2009-11-11</td>\n      <td>2009-11-11</td>\n      <td>PRV54895</td>\n      <td>50</td>\n      <td>PHY385898</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>915</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3870</td>\n      <td>970</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>100078</th>\n      <td>BENE100569</td>\n      <td>CLM602032</td>\n      <td>2009-09-27</td>\n      <td>2009-09-27</td>\n      <td>PRV54895</td>\n      <td>500</td>\n      <td>PHY368638</td>\n      <td>PHY368638</td>\n      <td>NaN</td>\n      <td>128</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1000</td>\n      <td>700</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>100079</th>\n      <td>BENE100677</td>\n      <td>CLM226299</td>\n      <td>2009-03-03</td>\n      <td>2009-03-03</td>\n      <td>PRV54895</td>\n      <td>200</td>\n      <td>PHY347629</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2761</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>820</td>\n      <td>280</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100080 rows × 55 columns</p>\n</div>"
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df = raw_df.rename(columns={'claim_id': 'id', 'is_fraud': 'target'})\n",
    "for col in benchmark_df.columns:\n",
    "    if ('claim_diag_code' in col) or ('claim_procedure_code' in col) or (col in ['claim_admit_diagnosis_code', 'diag_group_code']):\n",
    "        benchmark_df[col] = pd.factorize(benchmark_df[col])[0] + 1\n",
    "benchmark_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "benchmark_sample_df = benchmark_df.sample(frac=1).reset_index(drop=True)\n",
    "benchmark_sample_df.to_csv(os.path.join(outdir, 'raw.csv'), index=False)\n",
    "\n",
    "blob = bucket.blob(os.path.join('insurance_fraud', 'raw.csv'))\n",
    "blob.upload_from_filename(os.path.join(outdir, 'raw.csv'))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m106",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m106"
  },
  "instance_type": "ml.t3.medium",
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
