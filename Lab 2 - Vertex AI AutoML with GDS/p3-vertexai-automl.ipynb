{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rQ6G65n6OxV"
   },
   "source": [
    "# Part 3 : VertexAI Auto ML Embedding\n",
    "In this notebook, we'll use the awesome Vertex AI AutoML to train models with baseline and node embedding features\n",
    "\n",
    "## Outline\n",
    "1. VertexAI Setup\n",
    "2. Configure and Run Baseline Model\n",
    "3. Configure and Run Graph Embedding Based Model\n",
    "4. Results & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 9998,
     "status": "ok",
     "timestamp": 1681113488488,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "id": "zWcDg3rtFSTg"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install google-cloud-storage google-cloud-aiplatform python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681113149850,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "gather": {
     "logged": 1669345050388
    },
    "id": "7nS_fiKEFSTh"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDT66GlIFSTh"
   },
   "source": [
    "## Vertex AI Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaP3KG5bFSTh"
   },
   "source": [
    "Lets define the variables to connect to VertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681113268018,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "id": "ZBdYrgK4GHOH"
   },
   "outputs": [],
   "source": [
    "load_dotenv('config.env', override=True)\n",
    "REGION = os.getenv('GCLOUD_REGION')\n",
    "shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "\n",
    "STORAGE_BUCKET = PROJECT_ID + '-fsi'\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = PROJECT_ID\n",
    "\n",
    "baseline_data = os.path.join(\"gs://\", STORAGE_BUCKET, 'insurance_fraud', 'baseline.csv')\n",
    "embedding_data = os.path.join(\"gs://\", STORAGE_BUCKET, 'insurance_fraud', 'embedding.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create Tabular dataset objects for our baseline & embedding data below. These datasets refer to the Cloud Storage CSV files we just uploaded in the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "error",
     "timestamp": 1681113462053,
     "user": {
      "displayName": "Ezhil Vendhan",
      "userId": "03023723423453260577"
     },
     "user_tz": -480
    },
    "gather": {
     "logged": 1669345052512
    },
    "id": "7SoC49BeFSTh",
    "outputId": "5a2cd7ea-4a27-4140-fdb9-7112bc5f83a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TabularDataset\n",
      "Create TabularDataset backing LRO: projects/803648085855/locations/us-west1/datasets/133770982681739264/operations/1347999056630120448\n",
      "TabularDataset created. Resource name: projects/803648085855/locations/us-west1/datasets/133770982681739264\n",
      "To use this TabularDataset in another session:\n",
      "ds = aiplatform.TabularDataset('projects/803648085855/locations/us-west1/datasets/133770982681739264')\n",
      "\tDataset: \"claims-raw\"\n",
      "\tname: \"projects/803648085855/locations/us-west1/datasets/133770982681739264\"\n",
      "Creating TabularDataset\n",
      "Create TabularDataset backing LRO: projects/803648085855/locations/us-west1/datasets/6893674023364853760/operations/8175456091723792384\n",
      "TabularDataset created. Resource name: projects/803648085855/locations/us-west1/datasets/6893674023364853760\n",
      "To use this TabularDataset in another session:\n",
      "ds = aiplatform.TabularDataset('projects/803648085855/locations/us-west1/datasets/6893674023364853760')\n",
      "\tDataset: \"claims-embedding\"\n",
      "\tname: \"projects/803648085855/locations/us-west1/datasets/6893674023364853760\"\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "baseline_dataset = aiplatform.TabularDataset.create(\n",
    "    display_name=\"claims-raw\",\n",
    "    gcs_source=baseline_data,\n",
    ")\n",
    "baseline_dataset.wait()\n",
    "\n",
    "print(f'\\tDataset: \"{baseline_dataset.display_name}\"')\n",
    "print(f'\\tname: \"{baseline_dataset.resource_name}\"')\n",
    "\n",
    "embedding_dataset = aiplatform.TabularDataset.create(\n",
    "    display_name=\"claims-embedding\",\n",
    "    gcs_source=embedding_data,\n",
    ")\n",
    "embedding_dataset.wait()\n",
    "\n",
    "print(f'\\tDataset: \"{embedding_dataset.display_name}\"')\n",
    "print(f'\\tname: \"{embedding_dataset.resource_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and Run Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets define the numeric columns in our baseline dataset and define the job that will help us classify fraudulent claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['provider',\n",
       " 'potentialFraudInd',\n",
       " 'renalDiseaseIndicatorEnc',\n",
       " 'chronicCondAlzheimerEnc',\n",
       " 'chronicCondHeartfailureEnc',\n",
       " 'chronicCondKidneyDiseaseEnc',\n",
       " 'chronicCondCancerEnc',\n",
       " 'chronicCondObstrPulmonaryEnc',\n",
       " 'chronicCondDepressionEnc',\n",
       " 'chronicCondDiabetesEnc',\n",
       " 'chronicCondIschemicHeartEnc',\n",
       " 'chronicCondOsteoporasisEnc',\n",
       " 'chronicCondrheumatoidarthritisEnc',\n",
       " 'chronicCondstrokeEnc',\n",
       " 'claimCount']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cols = list(pd.read_csv(baseline_data).columns)\n",
    "baseline_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_baseline_cols = [i for i in baseline_cols if i not in ['provider', 'providerId']]\n",
    "baseline_column_specs = {column: \"numeric\" for column in num_baseline_cols}\n",
    "\n",
    "raw_job = aiplatform.AutoMLTabularTrainingJob(\n",
    "    display_name=\"train-fraud-baseline-automl\",\n",
    "    optimization_prediction_type=\"classification\",\n",
    "    column_specs=baseline_column_specs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we can run the model asyncroniously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_model = raw_job.run(\n",
    "    dataset=baseline_dataset,\n",
    "    target_column=\"potentialFraudInd\",\n",
    "    training_fraction_split=0.6,\n",
    "    validation_fraction_split=0.2,\n",
    "    test_fraction_split=0.2,\n",
    "    model_display_name=\"train-fraud-baseline-automl\",\n",
    "    disable_early_stopping=False,\n",
    "    budget_milli_node_hours=1000,\n",
    "    sync = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and Run Graph Embedding Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, let's define the classifier job for the embedding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['provider',\n",
       " 'potentialFraudInd',\n",
       " 'renalDiseaseIndicatorEnc',\n",
       " 'chronicCondAlzheimerEnc',\n",
       " 'chronicCondHeartfailureEnc',\n",
       " 'chronicCondKidneyDiseaseEnc',\n",
       " 'chronicCondCancerEnc',\n",
       " 'chronicCondObstrPulmonaryEnc',\n",
       " 'chronicCondDepressionEnc',\n",
       " 'chronicCondDiabetesEnc',\n",
       " 'chronicCondIschemicHeartEnc',\n",
       " 'chronicCondOsteoporasisEnc',\n",
       " 'chronicCondrheumatoidarthritisEnc',\n",
       " 'chronicCondstrokeEnc',\n",
       " 'claimCount',\n",
       " 'providerId',\n",
       " 'groupCodeEmb_0',\n",
       " 'groupCodeEmb_1',\n",
       " 'groupCodeEmb_2',\n",
       " 'groupCodeEmb_3',\n",
       " 'groupCodeEmb_4',\n",
       " 'groupCodeEmb_5',\n",
       " 'groupCodeEmb_6',\n",
       " 'groupCodeEmb_7',\n",
       " 'groupCodeEmb_8',\n",
       " 'groupCodeEmb_9',\n",
       " 'groupCodeEmb_10',\n",
       " 'groupCodeEmb_11',\n",
       " 'groupCodeEmb_12',\n",
       " 'groupCodeEmb_13',\n",
       " 'groupCodeEmb_14',\n",
       " 'groupCodeEmb_15',\n",
       " 'groupCodeEmb_16',\n",
       " 'groupCodeEmb_17',\n",
       " 'groupCodeEmb_18',\n",
       " 'groupCodeEmb_19',\n",
       " 'groupCodeEmb_20',\n",
       " 'groupCodeEmb_21',\n",
       " 'groupCodeEmb_22',\n",
       " 'groupCodeEmb_23',\n",
       " 'groupCodeEmb_24',\n",
       " 'groupCodeEmb_25',\n",
       " 'groupCodeEmb_26',\n",
       " 'groupCodeEmb_27',\n",
       " 'groupCodeEmb_28',\n",
       " 'groupCodeEmb_29',\n",
       " 'groupCodeEmb_30',\n",
       " 'groupCodeEmb_31',\n",
       " 'diagCodeEmb_0',\n",
       " 'diagCodeEmb_1',\n",
       " 'diagCodeEmb_2',\n",
       " 'diagCodeEmb_3',\n",
       " 'diagCodeEmb_4',\n",
       " 'diagCodeEmb_5',\n",
       " 'diagCodeEmb_6',\n",
       " 'diagCodeEmb_7',\n",
       " 'diagCodeEmb_8',\n",
       " 'diagCodeEmb_9',\n",
       " 'diagCodeEmb_10',\n",
       " 'diagCodeEmb_11',\n",
       " 'diagCodeEmb_12',\n",
       " 'diagCodeEmb_13',\n",
       " 'diagCodeEmb_14',\n",
       " 'diagCodeEmb_15',\n",
       " 'diagCodeEmb_16',\n",
       " 'diagCodeEmb_17',\n",
       " 'diagCodeEmb_18',\n",
       " 'diagCodeEmb_19',\n",
       " 'diagCodeEmb_20',\n",
       " 'diagCodeEmb_21',\n",
       " 'diagCodeEmb_22',\n",
       " 'diagCodeEmb_23',\n",
       " 'diagCodeEmb_24',\n",
       " 'diagCodeEmb_25',\n",
       " 'diagCodeEmb_26',\n",
       " 'diagCodeEmb_27',\n",
       " 'diagCodeEmb_28',\n",
       " 'diagCodeEmb_29',\n",
       " 'diagCodeEmb_30',\n",
       " 'diagCodeEmb_31']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_cols = list(pd.read_csv(embedding_data).columns)\n",
    "embedding_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embedding_cols = [i for i in embedding_cols if i not in ['provider', 'providerId']]\n",
    "embedding_column_specs = {column: \"numeric\" for column in num_embedding_cols}\n",
    "\n",
    "embedding_job = aiplatform.AutoMLTabularTrainingJob(\n",
    "    display_name=\"train-fraud-embeddings-automl\",\n",
    "    optimization_prediction_type=\"classification\",\n",
    "    column_specs=embedding_column_specs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-west1/training/5303439360996147200?project=803648085855\n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-west1/training/7645311167228805120?project=803648085855\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/1119595307168956416 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/3634855699055378432 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/1292983892822720512 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/1119595307168956416 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/3634855699055378432 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/1292983892822720512 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/1119595307168956416 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob run completed. Resource name: projects/803648085855/locations/us-west1/trainingPipelines/3634855699055378432\n",
      "Model available at projects/803648085855/locations/us-west1/models/3423562549545664512\n",
      "AutoMLTabularTrainingJob run completed. Resource name: projects/803648085855/locations/us-west1/trainingPipelines/1119595307168956416\n",
      "Model available at projects/803648085855/locations/us-west1/models/1874324277730213888\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/1292983892822720512 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob run completed. Resource name: projects/803648085855/locations/us-west1/trainingPipelines/1292983892822720512\n",
      "Model available at projects/803648085855/locations/us-west1/models/4178478437083643904\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/5303439360996147200 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLTabularTrainingJob projects/803648085855/locations/us-west1/trainingPipelines/7645311167228805120 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "embedding_model = embedding_job.run(\n",
    "    dataset=embedding_dataset,\n",
    "    target_column=\"potentialFraudInd\",\n",
    "    training_fraction_split=0.6,\n",
    "    validation_fraction_split=0.2,\n",
    "    test_fraction_split=0.2,\n",
    "    model_display_name=\"train-fraud-embeddings-automl\",\n",
    "    disable_early_stopping=False,\n",
    "    budget_milli_node_hours=1000,\n",
    "    sync = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 milli node hours, or one node hour, is the minimum budget that Vertex AI allows. These jobs will probably run for two to two and a half hours.\n",
    "\n",
    "We're going to move on while that runs. You can check on the job later in the Google Cloud Console to see the results. There's a link to the specific job in the output of the cells above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Once completed, you can start comparing the training results of both of your models. My results look like below.\n",
    "\n",
    "\n",
    "### Results for Baseline data (without embeddings)\n",
    "Here are the results for our Baseline data. \n",
    "![Baseline Metrics](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/baseline-metrics.png)\n",
    "\n",
    "![Baseline Confusion Matrix](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/baseline-confusion.png)\n",
    "\n",
    "These are the features ranked by their importance\n",
    "![Baseline Features](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/baseline-features.png)\n",
    "\n",
    "Let's see what value our embeddings add to:\n",
    "![Embedding Metrics](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/embedding-metrics.png)\n",
    "\n",
    "![Embedding Confusion Matrix](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/embedding-confusion.png)\n",
    "\n",
    "![Embedding Features](https://storage.googleapis.com/neo4j-datasets/insurance-claim/img/embedding-features.png)\n",
    "\n",
    "As you can see, embeddings fare much better with a higher for PR AUC value of 65% compared to baseline's 50%. Also, in terms of feature importance, many of the group code and diagnosis code embeddings are considered more important than raw features.\n",
    "\n",
    "## Conclusion\n",
    "Vertex AI made our job simpler by taking care of lots of overheads like hyper parameter tuning, feature importance etc. Once you find your best model using Vertex AI, you can also export the features like embeddings generated using GDS to Vertex AI Feature Store, deploy your model endpoints and start doing some predictions. \n",
    "\n",
    "Neo4j GDS has more than 70 algorithms in the toolbox which can help you do Graph Data Science in a memory optimised platform. While we covered only FastRP embedding algorithm here, there are few more like GraphSAGE, Node2Vec, HashGNN etc. The models & theories we tested out could be improved more. We will leave it to you to try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m106",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m106"
  },
  "instance_type": "ml.t3.medium",
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
